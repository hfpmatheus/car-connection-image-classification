{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils.common import *\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from tensorflow.keras.processing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(root_dir, current_dir, train_split=0.8):\n",
    "    change_to_current_dir(current_dir)\n",
    "    change_to_root_dir()\n",
    "\n",
    "    # Create train and val directories\n",
    "    train_dir = Path('artifacts/data/train')\n",
    "    val_dir = Path('artifacts/data/val')\n",
    "\n",
    "    # List car classes on data ingestion directory\n",
    "    car_folders = os.listdir(root_dir)\n",
    "\n",
    "    # Iterate through each class and move to train val directories\n",
    "    for folder in tqdm(car_folders):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        len_split = int(round((len(files) * train_split),0))\n",
    "\n",
    "        train_dataset = files[:len_split]\n",
    "        val_dataset = files[len_split:]\n",
    "\n",
    "        # Use list comprehension to give complete paths to each file\n",
    "        full_dataset = [os.path.join(root_dir, folder, file) for file in files]\n",
    "        train_dataset = [os.path.join(train_dir, folder, file) for file in train_dataset]\n",
    "        val_dataset = [os.path.join(val_dir, folder, file) for file in val_dataset]\n",
    "\n",
    "        # Appending train val dataset to match full dataset lenght\n",
    "        train_val_dataset = train_dataset + val_dataset\n",
    "\n",
    "        for root_path, split_path in tqdm(zip(full_dataset, train_val_dataset)):\n",
    "            split_dir, split_filename = os.path.split(split_path)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "            if not os.path.exists(split_path):\n",
    "                shutil.copy(root_path, split_path)\n",
    "\n",
    "    return train_dir, val_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_directory(path):\n",
    "#     # Delete the directory\n",
    "#     shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1174it [00:01, 763.96it/s]00<?, ?it/s]\n",
      "290it [00:00, 737.14it/s]:01<01:03,  1.55s/it]\n",
      "574it [00:00, 860.71it/s]:01<00:35,  1.14it/s]\n",
      "3131it [00:04, 779.23it/s]02<00:30,  1.27it/s]\n",
      "697it [00:01, 467.80it/s]:06<01:18,  2.08s/it]\n",
      "4121it [00:08, 493.98it/s]08<01:09,  1.87s/it]\n",
      "964it [00:02, 481.26it/s]:16<02:27,  4.09s/it]\n",
      "1311it [00:02, 480.76it/s]18<01:59,  3.42s/it]\n",
      "5079it [00:11, 442.56it/s]21<01:49,  3.21s/it]\n",
      "570it [00:00, 599.04it/s]:32<03:11,  5.81s/it]\n",
      "1345it [00:02, 473.08it/s]:33<02:17,  4.31s/it]\n",
      "91it [00:00, 235.04it/s]00:36<01:59,  3.87s/it]\n",
      "892it [00:01, 489.12it/s]0:37<01:24,  2.81s/it]\n",
      "4416it [00:09, 459.21it/s]:38<01:12,  2.52s/it]\n",
      "176it [00:00, 327.28it/s]0:48<02:10,  4.67s/it]\n",
      "2067it [00:04, 461.52it/s]:49<01:32,  3.43s/it]\n",
      "2675it [00:06, 413.89it/s]:53<01:37,  3.76s/it]\n",
      "2091it [00:04, 436.85it/s]:00<01:54,  4.58s/it]\n",
      "917it [00:02, 430.44it/s]1:04<01:51,  4.65s/it]\n",
      "1062it [00:01, 531.13it/s]:07<01:29,  3.90s/it]\n",
      "1196it [00:02, 493.60it/s]:09<01:13,  3.34s/it]\n",
      "2160it [00:03, 565.13it/s]:11<01:04,  3.08s/it]\n",
      "251it [00:00, 387.10it/s]1:15<01:09,  3.45s/it]\n",
      "960it [00:02, 441.31it/s]1:16<00:49,  2.62s/it]\n",
      "2125it [00:04, 497.36it/s]:18<00:44,  2.50s/it]\n",
      "1324it [00:02, 575.65it/s]:23<00:51,  3.05s/it]\n",
      "449it [00:00, 606.96it/s]1:25<00:45,  2.84s/it]\n",
      "1475it [00:03, 422.08it/s]:26<00:33,  2.22s/it]\n",
      "72it [00:00, 559.04it/s]01:29<00:36,  2.61s/it]\n",
      "3097it [00:06, 489.33it/s]:29<00:24,  1.87s/it]\n",
      "1059it [00:01, 542.71it/s]:36<00:38,  3.24s/it]\n",
      "644it [00:01, 437.72it/s]1:38<00:31,  2.86s/it]\n",
      "3881it [00:08, 449.28it/s]:39<00:24,  2.45s/it]\n",
      "1344it [00:03, 405.84it/s]:48<00:39,  4.36s/it]\n",
      "747it [00:01, 538.46it/s]1:52<00:32,  4.07s/it]\n",
      "277it [00:00, 527.18it/s]1:53<00:23,  3.30s/it]\